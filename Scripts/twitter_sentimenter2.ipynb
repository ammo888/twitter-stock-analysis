{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read twitter_handle.csv\n",
    "## if sentiment-twitter handle exist then im done\n",
    "## if it doesn't exist read twitter_handle.csv\n",
    "## sentiment-@twitter_handle.csv\n",
    "\n",
    "##receiving a timestamp, username, followers, text\n",
    "## add new column to sentiment score\n",
    "## resample into 15 minute buckets\n",
    "## average them (weighted average based on sentiment score and followers)\n",
    "## VWOP\n",
    "### weighted score = followers * sentiment score + followers * sentiment score / total number of followers\n",
    "\n",
    "## output file = time stamp, weigted sentiment score, total number of tweets, total number of followers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import hvplot as hv\n",
    "import spacy\n",
    "import asent\n",
    "from dframcy import dframcy\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Pandas DataFrame called sscore_df for sentiment score dataframe.\n",
    "\n",
    "sscore_df = pd.DataFrame()\n",
    "\n",
    "tweet_df = pd.read_csv(\"../Files/demo_tweets.csv\", index_col=\"date\", infer_datetime_format=True, parse_dates=True)\n",
    "\n",
    "tweet_df.dropna(inplace=True)\n",
    "\n",
    "tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank('en')\n",
    "nlp.add_pipe('sentencizer')\n",
    "nlp.add_pipe('asent_en_v1')\n",
    "nlp\n",
    "tweet_df[\"Sentiment_asent\"] = tweet_df[\"tweet\"].apply(lambda tweet: nlp(tweet)._.polarity.compound)\n",
    "\n",
    "tweet_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp2 = spacy.load('en_core_web_sm')\n",
    "nlp2.add_pipe('spacytextblob')\n",
    "nlp2\n",
    "tweet_df['Sentiment_textblob'] = tweet_df['tweet'].apply(lambda tweet: nlp2(tweet)._.blob.polarity)\n",
    "\n",
    "\n",
    "\n",
    "#tweet_df.drop(columns=\"Sentiment_1\", inplace=True)\n",
    "\n",
    "tweet_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df['average_sentiment'] = tweet_df[[\"Sentiment_asent\", \"Sentiment_textblob\"]].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### weighted score = followers * sentiment score + followers * sentiment score / total number of followers\n",
    "\n",
    "tweet_df['weighted_sentiment'] = (tweet_df[\"followers\"])*(tweet_df[\"average_sentiment\"]).sum()/tweet_df[\"followers\"].sum()\n",
    " \n",
    "tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet, polarity = tweet_text2[20]\n",
    "print(polarity)\n",
    "asent.visualize(nlp(tweet), style='prediction')\n",
    "asent.visualize(nlp(tweet), style='analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rand_sent = np.random.randint(-1, 1, 365, int)\n",
    "rand_sent.tolist()\n",
    "sscore_df[\"score\"] = rand_sent \n",
    "\n",
    "date = pd.date_range(start='09/25/2021',end='09/25/2022',periods=365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df['tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sscore_df[\"date\"] = date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sscore_df.reset_index()\n",
    "sscore_df.set_index(\"date\")\n",
    "sscore_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path  \n",
    "filepath = Path('C:\\Users\\BlackGod\\Desktop\\NWU_Bootcamp\\twitter-stock-analysis\\Files')  \n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "tweet_df.to_csv(filepath)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import questionary as q\n",
    "import pandas as pd\n",
    "import pandas_market_calendars as mcal\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import hvplot as hv\n",
    "import spacy\n",
    "import asent\n",
    "from dframcy import dframcy\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "\n",
    "def get_analysis_date():\n",
    "    time_format = \"%Y-%m-%d\"\n",
    "    nyse_cal = mcal.get_calendar('NYSE')\n",
    "\n",
    "    today = pd.Timestamp.today()\n",
    "    start_date = (today - pd.Timedelta(730, \"d\")).strftime(time_format)\n",
    "    end_date = today.strftime(time_format)\n",
    "\n",
    "    valid_nyse_days = nyse_cal.valid_days(start_date=start_date, end_date=end_date)\n",
    "\n",
    "    analysis_date = q.autocomplete(\"Pick a stock market date (yyyy-MM-dd format) within the last 2 years for analysis:\",\n",
    "                                   choices=[d.strftime(time_format) for d in valid_nyse_days]).ask()\n",
    "\n",
    "    return analysis_date\n",
    "\n",
    "\n",
    "def user_input():\n",
    "    print(\"Welcome to the twitter sentiment vs. stock price analysis tool!\")\n",
    "\n",
    "    twitter_user = q.text(\"Please enter the twitter user handle of interest:\").ask()\n",
    "    stock_ticker = q.text(\"Please enter the stock ticker of interest:\").ask()\n",
    "    stock_ticker = stock_ticker.upper()\n",
    "\n",
    "    confirmation = q.confirm(f\"Do you want to proceed analysis for twitter user @{twitter_user} and stock ticker ^{stock_ticker}?\").ask()\n",
    "\n",
    "    if not confirmation:\n",
    "        print(\"Ok! Exiting script...\")\n",
    "        sys.exit(0)\n",
    "\n",
    "    analysis_date = get_analysis_date()\n",
    "\n",
    "    return twitter_user, stock_ticker, analysis_date\n",
    "\n",
    "\n",
    "'''\n",
    "if __name__ == '__main__':\n",
    "    twitter_user, stock_ticker, analysis_date = user_input()\n",
    "    print(f\"Analyzing twitter sentiment of @{twitter_user} against stock price of ^{stock_ticker} on {analysis_date}...\")\n",
    "'''\n",
    "def get_tweet_sentiment():\n",
    "    print(\".....\")\n",
    "\n",
    "    tweet_df = pd.read_csv(\"../Files/demo_tweets.csv\", index_col=\"date\", infer_datetime_format=True, parse_dates=True)\n",
    "    tweet_df.dropna(inplace=True)\n",
    "\n",
    "# Adding spacy model and the sentencizer and asent pipeline\n",
    "\n",
    "    nlp = spacy.blank('en')\n",
    "    nlp.add_pipe('sentencizer')\n",
    "    nlp.add_pipe('asent_en_v1')\n",
    "\n",
    "    tweet_df[\"Sentiment_asent\"] = tweet_df[\"tweet\"].apply(lambda tweet: nlp(tweet)._.polarity.compound)\n",
    "\n",
    "    nlp2 = spacy.load('en_core_web_sm')\n",
    "    nlp2.add_pipe('spacytextblob')\n",
    "    nlp2\n",
    "\n",
    "    tweet_df['Sentiment_textblob'] = tweet_df['tweet'].apply(lambda tweet: nlp2(tweet)._.blob.polarity)\n",
    "    \n",
    "    tweet_df['average_sentiment'] = tweet_df[[\"Sentiment_asent\", \"Sentiment_textblob\"]].mean(axis=1)\n",
    "\n",
    "# weighted score = followers * sentiment score + followers * sentiment score / total number of followers\n",
    "\n",
    "    tweet_df['weighted_sentiment'] = (tweet_df[\"followers\"])*(tweet_df[\"average_sentiment\"]).sum()/tweet_df[\"followers\"].sum()\n",
    "\n",
    "    return tweet_df\n",
    "\n",
    "\n",
    "    from pathlib import Path  \n",
    "    filepath = Path('/twitter-stock-analysis/Files')  \n",
    "    filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "    tweet_df.to_csv(filepath) \n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tweet_sentiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import questionary as q\n",
    "import pandas as pd\n",
    "import pandas_market_calendars as mcal\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import hvplot as hv\n",
    "import spacy\n",
    "import asent\n",
    "from dframcy import dframcy\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "\n",
    "def get_analysis_date():\n",
    "    time_format = \"%Y-%m-%d\"\n",
    "    nyse_cal = mcal.get_calendar('NYSE')\n",
    "\n",
    "    today = pd.Timestamp.today()\n",
    "    start_date = (today - pd.Timedelta(730, \"d\")).strftime(time_format)\n",
    "    end_date = today.strftime(time_format)\n",
    "\n",
    "    valid_nyse_days = nyse_cal.valid_days(start_date=start_date, end_date=end_date)\n",
    "\n",
    "    analysis_date = q.autocomplete(\"Pick a stock market date (yyyy-MM-dd format) within the last 2 years for analysis:\",\n",
    "                                   choices=[d.strftime(time_format) for d in valid_nyse_days]).ask()\n",
    "\n",
    "    return analysis_date\n",
    "\n",
    "\n",
    "def user_input():\n",
    "    print(\"Welcome to the twitter sentiment vs. stock price analysis tool!\")\n",
    "\n",
    "    twitter_user = q.text(\"Please enter the twitter user handle of interest:\").ask()\n",
    "    stock_ticker = q.text(\"Please enter the stock ticker of interest:\").ask()\n",
    "    stock_ticker = stock_ticker.upper()\n",
    "\n",
    "    confirmation = q.confirm(f\"Do you want to proceed analysis for twitter user @{twitter_user} and stock ticker ^{stock_ticker}?\").ask()\n",
    "\n",
    "    if not confirmation:\n",
    "        print(\"Ok! Exiting script...\")\n",
    "        sys.exit(0)\n",
    "\n",
    "    analysis_date = get_analysis_date()\n",
    "\n",
    "    return twitter_user, stock_ticker, analysis_date\n",
    "\n",
    "'''\n",
    "if __name__ == '__main__':\n",
    "    twitter_user, stock_ticker, analysis_date = user_input()\n",
    "    print(f\"Analyzing twitter sentiment of @{twitter_user} against stock price of ^{stock_ticker} on {analysis_date}...\")\n",
    "'''\n",
    "def get_tweet_sentiment():\n",
    "    print(\".....\")\n",
    "\n",
    "    tweet_df = pd.read_csv(\"../Files/demo_tweets.csv\", index_col=\"date\", infer_datetime_format=True, parse_dates=True)\n",
    "    tweet_df.dropna(inplace=True)\n",
    "\n",
    "# Adding spacy model and the sentencizer and asent pipeline\n",
    "\n",
    "    nlp = spacy.blank('en')\n",
    "    nlp.add_pipe('sentencizer')\n",
    "    nlp.add_pipe('asent_en_v1')\n",
    "\n",
    "    tweet_df[\"Sentiment_asent\"] = tweet_df[\"tweet\"].apply(lambda tweet: nlp(tweet)._.polarity.compound)\n",
    "\n",
    "    nlp2 = spacy.load('en_core_web_sm')\n",
    "    nlp2.add_pipe('spacytextblob')\n",
    "    nlp2\n",
    "\n",
    "    tweet_df['Sentiment_textblob'] = tweet_df['tweet'].apply(lambda tweet: nlp2(tweet)._.blob.polarity)\n",
    "    \n",
    "    tweet_df['average_sentiment'] = tweet_df[[\"Sentiment_asent\", \"Sentiment_textblob\"]].mean(axis=1)\n",
    "\n",
    "# weighted score = followers * sentiment score + followers * sentiment score / total number of followers\n",
    "\n",
    "    tweet_df['weighted_sentiment'] = (tweet_df[\"followers\"])*(tweet_df[\"average_sentiment\"]).sum()/tweet_df[\"followers\"].sum()\n",
    "\n",
    "    output_file = tweet_df.to_csv('output.csv', index = True)\n",
    "    print('\\nCSV String:\\n', output_file)\n",
    "   \n",
    "    return tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".....\n",
      "\n",
      "CSV String:\n",
      " None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>followers</th>\n",
       "      <th>tweet</th>\n",
       "      <th>Sentiment_asent</th>\n",
       "      <th>Sentiment_textblob</th>\n",
       "      <th>average_sentiment</th>\n",
       "      <th>weighted_sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-09-25</th>\n",
       "      <td>YLQI</td>\n",
       "      <td>7857.0</td>\n",
       "      <td>Is history repeating itself...?#DONTNORMALIZEH...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.191978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-26</th>\n",
       "      <td>HTOQ</td>\n",
       "      <td>4586.0</td>\n",
       "      <td>@barackobama Thank you for your incredible gra...</td>\n",
       "      <td>0.680111</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.790056</td>\n",
       "      <td>0.112055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-27</th>\n",
       "      <td>WFWO</td>\n",
       "      <td>1621.0</td>\n",
       "      <td>Life goals. https://t.co/XIn1qKMKQl</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-28</th>\n",
       "      <td>PLVO</td>\n",
       "      <td>7050.0</td>\n",
       "      <td>Me right now üôèüèª https://t.co/gW55C1wrwd</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.172260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-29</th>\n",
       "      <td>QVCD</td>\n",
       "      <td>1141.0</td>\n",
       "      <td>SISTERS ARE DOIN' IT FOR THEMSELVES! üôåüèªüí™üèª‚ù§Ô∏è ht...</td>\n",
       "      <td>0.353378</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.176689</td>\n",
       "      <td>0.027879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-19</th>\n",
       "      <td>CWMM</td>\n",
       "      <td>7763.0</td>\n",
       "      <td>@katyscrush hola bb</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.189682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-20</th>\n",
       "      <td>QHFE</td>\n",
       "      <td>3946.0</td>\n",
       "      <td>@waIkingonair yes this</td>\n",
       "      <td>0.401924</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200962</td>\n",
       "      <td>0.096417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-21</th>\n",
       "      <td>JMLA</td>\n",
       "      <td>1194.0</td>\n",
       "      <td>@katycatsophia @camilasviews JK ily</td>\n",
       "      <td>0.792514</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.396257</td>\n",
       "      <td>0.029174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-22</th>\n",
       "      <td>QLGC</td>\n",
       "      <td>1430.0</td>\n",
       "      <td>@katycatsophia @camilasviews don't make me com...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.077778</td>\n",
       "      <td>-0.038889</td>\n",
       "      <td>0.034941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-23</th>\n",
       "      <td>QNRN</td>\n",
       "      <td>29.0</td>\n",
       "      <td>@Eduardo_KatyCat this is art bb</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>364 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           username  followers  \\\n",
       "date                             \n",
       "2021-09-25     YLQI     7857.0   \n",
       "2021-09-26     HTOQ     4586.0   \n",
       "2021-09-27     WFWO     1621.0   \n",
       "2021-09-28     PLVO     7050.0   \n",
       "2021-09-29     QVCD     1141.0   \n",
       "...             ...        ...   \n",
       "2022-09-19     CWMM     7763.0   \n",
       "2022-09-20     QHFE     3946.0   \n",
       "2022-09-21     JMLA     1194.0   \n",
       "2022-09-22     QLGC     1430.0   \n",
       "2022-09-23     QNRN       29.0   \n",
       "\n",
       "                                                        tweet  \\\n",
       "date                                                            \n",
       "2021-09-25  Is history repeating itself...?#DONTNORMALIZEH...   \n",
       "2021-09-26  @barackobama Thank you for your incredible gra...   \n",
       "2021-09-27                Life goals. https://t.co/XIn1qKMKQl   \n",
       "2021-09-28            Me right now üôèüèª https://t.co/gW55C1wrwd   \n",
       "2021-09-29  SISTERS ARE DOIN' IT FOR THEMSELVES! üôåüèªüí™üèª‚ù§Ô∏è ht...   \n",
       "...                                                       ...   \n",
       "2022-09-19                                @katyscrush hola bb   \n",
       "2022-09-20                             @waIkingonair yes this   \n",
       "2022-09-21                @katycatsophia @camilasviews JK ily   \n",
       "2022-09-22  @katycatsophia @camilasviews don't make me com...   \n",
       "2022-09-23                    @Eduardo_KatyCat this is art bb   \n",
       "\n",
       "            Sentiment_asent  Sentiment_textblob  average_sentiment  \\\n",
       "date                                                                 \n",
       "2021-09-25         0.000000            0.000000           0.000000   \n",
       "2021-09-26         0.680111            0.900000           0.790056   \n",
       "2021-09-27         0.000000            0.000000           0.000000   \n",
       "2021-09-28         0.000000            0.285714           0.142857   \n",
       "2021-09-29         0.353378            0.000000           0.176689   \n",
       "...                     ...                 ...                ...   \n",
       "2022-09-19         0.000000            0.000000           0.000000   \n",
       "2022-09-20         0.401924            0.000000           0.200962   \n",
       "2022-09-21         0.792514            0.000000           0.396257   \n",
       "2022-09-22         0.000000           -0.077778          -0.038889   \n",
       "2022-09-23         0.000000            0.000000           0.000000   \n",
       "\n",
       "            weighted_sentiment  \n",
       "date                            \n",
       "2021-09-25            0.191978  \n",
       "2021-09-26            0.112055  \n",
       "2021-09-27            0.039608  \n",
       "2021-09-28            0.172260  \n",
       "2021-09-29            0.027879  \n",
       "...                        ...  \n",
       "2022-09-19            0.189682  \n",
       "2022-09-20            0.096417  \n",
       "2022-09-21            0.029174  \n",
       "2022-09-22            0.034941  \n",
       "2022-09-23            0.000709  \n",
       "\n",
       "[364 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_tweet_sentiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7e13a2bd7e601ba20958ae880a71f2cd8b54869ebdd5c69f34de7dded58785d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
